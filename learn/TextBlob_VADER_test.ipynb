{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis TextBlob and VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('./raw-data/train_tweets.csv')\n",
    "training_df = training_df[['label', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__ TextBlob Results __\n",
      "positive accuracy: 86.07\n",
      "negative accuracy: 25.91\n",
      "neutral percent: 0.00\n",
      "elapsed time: 6\n",
      "__ Vader Results __\n",
      "positive accuracy: 86.07\n",
      "negative accuracy: 25.91\n",
      "neutral percent: 0.00\n",
      "elapsed time: 5\n"
     ]
    }
   ],
   "source": [
    "# -1 negative sentiment, 0 neutral, 1 positive (no inbetweens)\n",
    "def checkSentimentAccuracy(sentence_list, actual_list, analyzer):\n",
    "    results = {\n",
    "        'pos_match': 0,\n",
    "        'pos_count': 0,\n",
    "        'neg_match': 0,\n",
    "        'neg_count': 0,\n",
    "        'neu_count': 0\n",
    "    }\n",
    "    \n",
    "    for sentence, actual in zip(sentence_list, actual_list):\n",
    "        if actual == 0:\n",
    "            results['pos_count'] += 1\n",
    "        else:\n",
    "            results['neg_count'] += 1\n",
    "            \n",
    "        score = analyzer(sentence)\n",
    "        \n",
    "        if score == 1 and actual == 0:\n",
    "            results['pos_match'] += 1\n",
    "        elif score == -1 and actual == 1:\n",
    "            results['neg_match'] += 1\n",
    "        elif score == 0:\n",
    "            results['neu_count'] += 1\n",
    "            \n",
    "    return results\n",
    "\n",
    "def printAccuracyResults(results):\n",
    "    pos_accuracy = tb_results['pos_match']/tb_results['pos_count']*100\n",
    "    neg_accuracy = tb_results['neg_match']/tb_results['neg_count']*100\n",
    "    neutral_percent = tb_results['neu_count']/(tb_results['neg_count'] + tb_results['pos_count'])*100\n",
    "    print('positive accuracy: %.2f' % pos_accuracy)\n",
    "    print('negative accuracy: %.2f' % neg_accuracy)\n",
    "    print('neutral percent: %.2f' % neutral_percent)\n",
    "\n",
    "textblob_threshold = 0\n",
    "vader_threshold = 0\n",
    "\n",
    "def textblobAnalyze(sentence):\n",
    "    analysis = TextBlob(sentence)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    score = 0\n",
    "    if polarity >= textblob_threshold:\n",
    "        score = 1\n",
    "    elif polarity < 0:\n",
    "        score = -1\n",
    "        \n",
    "    return score\n",
    "\n",
    "v_analyzer = SentimentIntensityAnalyzer()\n",
    "def vaderAnalyze(sentence):\n",
    "    analysis = v_analyzer.polarity_scores(sentence)\n",
    "    raw_score = analysis['compound']\n",
    "    score = 0\n",
    "    if raw_score >= vader_threshold:\n",
    "        score = 1\n",
    "    elif raw_score < 0:\n",
    "        score = -1\n",
    "        \n",
    "    return score\n",
    "\n",
    "test_sentence = 'Today is a horrible day.'\n",
    "\n",
    "# print(textblobAnalyze(test_sentence))\n",
    "# print(vaderAnalyze(test_sentence))\n",
    "\n",
    "tb_start = time()\n",
    "tb_results = checkSentimentAccuracy(training_df['tweet'], training_df['label'], textblobAnalyze)\n",
    "tb_diff = time() - tb_start\n",
    "v_start = time()\n",
    "v_results = checkSentimentAccuracy(training_df['tweet'], training_df['label'], vaderAnalyze)\n",
    "v_diff = time() - v_start\n",
    "print('__ TextBlob Results __')\n",
    "printAccuracyResults(tb_results)\n",
    "print('elapsed time: %i' % tb_diff)\n",
    "print('__ Vader Results __')\n",
    "printAccuracyResults(v_results)\n",
    "print('elapsed time: %i' % v_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n"
     ]
    }
   ],
   "source": [
    "print(v_analyzer.polarity_scores('Today is a horrible day.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Given the results above, I am not sure I can rely on a negative analysis, but at least the positive match accuracy is above 80% and that will have to do. Also when tested with the string 'Today is a horrible day' it does return a negative result.\n",
    "\n",
    "VADER is slightly faster, so I will use that module as it has aditional analysis data that might be useful. I used 'compound' for the test, but there is also a negative, positive, and neutral score.\n",
    "\n",
    "It should also be noted that textblob does other useful tasks like tokenization and subjectivity scoring which could also be useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
